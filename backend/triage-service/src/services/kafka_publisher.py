"""
Kafka Publisher for Audit Events
Elite Implementation Standard v2.0.0

Publishes TriageAudit events to Kafka topic: learning.events
Implements reliable event publishing with fallback.
"""

import json
import time
from typing import Dict, Optional, List
from dataclasses import asdict
from datetime import datetime
from enum import Enum


class KafkaTopic(Enum):
    """Available Kafka topics"""
    AUDIT_EVENTS = "learning.events.audit.triage"
    SECURITY_EVENTS = "learning.events.security"
    DLQ_EVENTS = "learning.events.dlq.triage-service"
    PERFORMANCE_METRICS = "learning.events.metrics.triage"


class KafkaPublisher:
    """
    Kafka event publisher with mock fallback

    Publishes:
    - TriageAudit events (for compliance)
    - Security events (for monitoring)
    - DLQ events (for failure tracking)
    - Performance metrics (for optimization)
    """

    def __init__(self, use_mock: bool = True):
        self.use_mock = use_mock
        self.topics = {topic.value: [] for topic in KafkaTopic}

        if not use_mock:
            try:
                from kafka import KafkaProducer
                self.producer = KafkaProducer(
                    bootstrap_servers=['localhost:9092'],
                    value_serializer=lambda v: json.dumps(v).encode('utf-8'),
                    key_serializer=lambda k: k.encode('utf-8') if k else None,
                    retries=3,
                    acks='all',  # Wait for all replicas
                    enable_idempotence=True
                )
                print("Kafka producer initialized")
            except ImportError:
                print("Kafka library not available, using mock mode")
                self.use_mock = True
                self.producer = None
        else:
            self.producer = None

    def publish_audit_event(self, audit_data: Dict, key: Optional[str] = None) -> Dict:
        """
        Publish audit event to Kafka

        Args:
            audit_data: TriageAudit data
            key: Optional partition key (e.g., student_id)

        Returns:
            Publish result metadata
        """
        topic = KafkaTopic.AUDIT_EVENTS.value

        # Add publish timestamp
        enriched_data = {
            **audit_data,
            "published_at": datetime.utcnow().isoformat(),
            "broker": "mock" if self.use_mock else "kafka"
        }

        return self._publish(topic, enriched_data, key)

    def publish_security_event(
        self,
        event_type: str,
        student_id: str,
        details: Dict,
        severity: str = "medium"
    ) -> Dict:
        """
        Publish security event

        Args:
            event_type: Type of security event
            student_id: Student involved
            details: Event details
            severity: Severity level

        Returns:
            Publish result metadata
        """
        topic = KafkaTopic.SECURITY_EVENTS.value

        event_data = {
            "event_type": event_type,
            "student_id": student_id,
            "timestamp": datetime.utcnow().isoformat(),
            "severity": severity,
            "details": details,
            "service": "triage-service"
        }

        return self._publish(topic, event_data, key=student_id)

    def publish_dlq_event(self, original_request: Dict, failure_reason: str) -> Dict:
        """
        Publish event to dead letter queue

        Args:
            original_request: Failed request data
            failure_reason: Why it failed

        Returns:
            Publish result metadata
        """
        topic = KafkaTopic.DLQ_EVENTS.value

        dlq_data = {
            "original_request": original_request,
            "failure_reason": failure_reason,
            "timestamp": datetime.utcnow().isoformat(),
            "retry_count": 0,
            "service": "triage-service"
        }

        return self._publish(topic, dlq_data, key=original_request.get("request_id"))

    def publish_performance_metrics(self, metrics: Dict) -> Dict:
        """
        Publish performance metrics

        Args:
            metrics: Performance data

        Returns:
            Publish result metadata
        """
        topic = KafkaTopic.PERFORMANCE_METRICS.value

        metric_data = {
            "metrics": metrics,
            "timestamp": datetime.utcnow().isoformat(),
            "service": "triage-service",
            "version": "1.0.0"
        }

        return self._publish(topic, metric_data)

    def _publish(self, topic: str, data: Dict, key: Optional[str] = None) -> Dict:
        """Internal publish method with fallback logic"""
        if self.use_mock or self.producer is None:
            # Mock mode - store in memory
            if topic in self.topics:
                self.topics[topic].append(data)

            result = {
                "status": "published_mock",
                "topic": topic,
                "partition": 0,
                "offset": len(self.topics.get(topic, [])) - 1,
                "timestamp": datetime.utcnow().isoformat(),
                "key": key,
                "broker": "mock"
            }

            # Log for visibility
            print(f"KAFKA [{topic}]: {json.dumps(data, indent=2)}")

        else:
            # Real Kafka publishing
            try:
                future = self.producer.send(
                    topic,
                    key=key.encode('utf-8') if key else None,
                    value=data
                )
                record_metadata = future.get(timeout=10)

                result = {
                    "status": "published",
                    "topic": record_metadata.topic,
                    "partition": record_metadata.partition,
                    "offset": record_metadata.offset,
                    "timestamp": datetime.utcnow().isoformat(),
                    "key": key,
                    "broker": "kafka"
                }

                # Flush to ensure delivery
                self.producer.flush()

            except Exception as e:
                # Fallback to mock mode if Kafka fails
                print(f"Kafka publish failed: {e}, falling back to mock")
                if topic in self.topics:
                    self.topics[topic].append(data)

                result = {
                    "status": "fallback",
                    "topic": topic,
                    "error": str(e),
                    "broker": "mock"
                }

        return result

    def get_topic_stats(self) -> Dict:
        """Get statistics for all topics"""
        return {
            topic: {
                "message_count": len(messages),
                "last_message": messages[-1]["timestamp"] if messages else None
            }
            for topic, messages in self.topics.items()
            if messages
        }

    def get_messages(self, topic: str, limit: int = 100) -> List[Dict]:
        """Get messages from topic (mock mode)"""
        if topic in self.topics:
            messages = self.topics[topic]
            if limit < len(messages):
                return messages[-limit:]
            return messages
        return []

    def search_events(self, topic: str, query: Dict) -> List[Dict]:
        """Search events by criteria (mock mode)"""
        messages = self.get_messages(topic, limit=10000)

        results = []
        for msg in messages:
            match = True
            for key, value in query.items():
                if key not in msg or msg[key] != value:
                    match = False
                    break
            if match:
                results.append(msg)

        return results

    def clear_topic(self, topic: str) -> bool:
        """Clear all messages from topic (for testing)"""
        if topic in self.topics:
            self.topics[topic].clear()
            return True
        return False


# Global publisher instance
kafka_publisher = KafkaPublisher(use_mock=True)


def publish_audit(audit_data: Dict, key: Optional[str] = None) -> Dict:
    """Convenience function for audit events"""
    return kafka_publisher.publish_audit_event(audit_data, key)


def publish_security(event_type: str, student_id: str, details: Dict, severity: str = "medium") -> Dict:
    """Convenience function for security events"""
    return kafka_publisher.publish_security_event(event_type, student_id, details, severity)


def publish_dlq(original_request: Dict, failure_reason: str) -> Dict:
    """Convenience function for DLQ events"""
    return kafka_publisher.publish_dlq_event(original_request, failure_reason)


def publish_metrics(metrics: Dict) -> Dict:
    """Convenience function for metrics events"""
    return kafka_publisher.publish_performance_metrics(metrics)


if __name__ == "__main__":
    # Test Kafka publisher
    print("=== Kafka Publisher Test ===")

    # Test 1: Audit event
    audit_data = {
        "audit_id": "audit-12345",
        "request_id": "req-12345",
        "student_id": "student-67890",
        "intent": "syntax_help",
        "efficiency": 98.7,
        "timestamp": datetime.utcnow().isoformat()
    }

    result1 = kafka_publisher.publish_audit_event(audit_data, key="student-67890")
    print(f"Audit publish: {result1['status']}")

    # Test 2: Security event
    result2 = kafka_publisher.publish_security_event(
        "RATE_LIMIT_EXCEEDED",
        "student-12345",
        {"limit": 100, "window": "minute"},
        "high"
    )
    print(f"Security publish: {result2['status']}")

    # Test 3: DLQ event
    result3 = kafka_publisher.publish_dlq_event(
        {"request_id": "req-999", "query": "failed query"},
        "Circuit breaker open"
    )
    print(f"DLQ publish: {result3['status']}")

    # Test 4: Performance metrics
    metrics = {
        "avg_latency": 25.5,
        "p95": 45.0,
        "throughput": 150
    }
    result4 = kafka_publisher.publish_performance_metrics(metrics)
    print(f"Metrics publish: {result4['status']}")

    # Show stats
    print(f"\nTopic Stats: {json.dumps(kafka_publisher.get_topic_stats(), indent=2)}")

    # Show audit messages
    audit_messages = kafka_publisher.get_messages("learning.events.audit.triage")
    print(f"\nAudit Messages: {len(audit_messages)}")

    print("\nâœ… Kafka publishing working correctly")